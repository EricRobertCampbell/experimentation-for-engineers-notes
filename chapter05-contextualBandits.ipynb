{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandints - Making targeted decisions\n",
    "\n",
    "So far: A/B testing and multi-armed bandits can evaluate arbitrary changes, and RSM optimizes a small number of continuous parameters.\n",
    "\n",
    "Contextual bandits can optimize multiple (potentially illions) of system parameters  -but only for a narrowly defined type of system consisting of\n",
    "1. a model that predicts the short term businesss-metric outcome of a decision\n",
    "1. a component that makes decisions based on the model's predictions\n",
    "\n",
    "Basic outline: optimize with a greedy algorithm, then epsilon-greedy, then Thompson sampling.\n",
    "\n",
    "## Model a  business metric offline to make decisions online\n",
    "\n",
    "First-pass attempt at building a contextual bandit:\n",
    "1. Fit a rediction model from logged data\n",
    "1. Make decisions in production based on the model's predictions\n",
    "\n",
    "This is called a *greedy contextual bandit* \n",
    "\n",
    "The contextual bandit (CB) is typidifed by a recommender system (suggests content - e.g. blogs, movies, songs, &c.). \n",
    "\n",
    "Consists of an offline part where you fit a business metric predictor on logged data and on online part where you then make prediction and take actions based on the training (then iterate).\n",
    "\n",
    "### Model the business=metric outcome of a decision\n",
    "\n",
    "Say you're an ML engineer working on a social media app. It shows a piece of text (a 'post') to the user, selected from a larger group called the 'inventory'.\n",
    "\n",
    "Our goal is to show users what they want to see, as measured by engagement. For us, that is `viewing time`, and is the business metric that we'll be focusing on.\n",
    "\n",
    "We want to model\n",
    "\n",
    "$$\n",
    "\\text{viewing time} = f(\\text{user}, \\text{post})\n",
    "$$\n",
    "\n",
    "In CB-speak, the user is called the *context*, the act of displaying the post is the *action*, and the viewing time is the *reward*.\n",
    "\n",
    "#### Simulate the viewing time\n",
    "\n",
    "Let's simulate the measurement of viewing time. Then we'll fit a prediction model to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def measure_viewing_time(context, action_weights):\n",
    "    return np.exp(context * action_weights).mean() + 0.1 * np.random.normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate the viewing time as a random number with mean depending on the `context` and `viewing_weights`.\n",
    "\n",
    "The `context` is a vecton containing the features that describe the user. They mey be demographic information, interest, *c.\n",
    "\n",
    "The `action_weights` are different. Thye model how a user (`context`) respondes to different posts. We can't observe `action_weights`, they're just here to make a simulator. We'll set it equal to the output of `np.random.normal` and leave it unchanged for the rest.\n",
    "\n",
    "#### Fit the prediction model\n",
    "\n",
    "You fit the prediction model offline periodically (say weekly or whatnot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, context, action, reward) -> None:\n",
    "        self.context = context # the user\n",
    "        self.action = action # displayed post\n",
    "        self.reward = reward # viewing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each post, model the reward (`viewing time`) as a linear function of the context vector:\n",
    "\n",
    "$$\n",
    "\\text{reward} = \\beta * \\text{context} + \\epsilon\n",
    "$$\n",
    "\n",
    "or, if `y = reward` and `X = context`, then\n",
    "\n",
    "$$\n",
    "y = X \\beta + epsilon\n",
    "$$\n",
    "\n",
    "This looks like linear regression! We'll run one linear regression for each of the `num_actions` posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_logs_by_action(num_actions, logs):\n",
    "    samples_y = [[] for _ in range(num_actions)]\n",
    "    samples_x = [[] for _ in range(num_actions)]\n",
    "    for sample in logs:\n",
    "        samples_y[samples.action].append(sample.reward)\n",
    "        samples_x[samples.action].append(sample.context)\n",
    "    return sample_x, samples_y\n",
    "\n",
    "def build_models(num_features, samples_y, samples_x):\n",
    "    \"\"\" Build a model performs one linear regression on each of the num_actions set of samples, given that there are num_features features in each context (user) \"\"\"\n",
    "    betas = []\n",
    "    for y, x in zip(samples_y, samples_x):\n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        if len(y) > 0:\n",
    "            beta = np.linalg.pinv(X.T @ X) @ (X.T @ y)\n",
    "        else:\n",
    "            beta = np.zeros(shape=(num_features,))\n",
    "        betas.append(beta)\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Note that we are using `pinv` instead of `inv`. This calculates the pseudo-inverse, which is equal to the inverser when it exists but also exists for some other cases, like when there are too few samples of where the regressors are too similar to each other. We are thinking of it like a more 'robust' version of the inverse that is useful for linear regressions.\n",
    "\n",
    "---\n",
    "\n",
    "So now we have the components for the offline portion - now we need the online one.\n",
    "\n",
    "### Add the decision-making component\n",
    "\n",
    "Since we're using the *greedy* algorithm, when a user requests a post, we'll check each post for the predicted viewing time (reward) and show them that one!\n",
    "\n",
    "In CB-speak, the decision-making component is called a *policy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderGreedy:\n",
    "    def __init__(self, num_features, num_actions) -> None:\n",
    "        self._num_features = num_features\n",
    "        self._num_actions = num_actions\n",
    "    \n",
    "    def reset(self):\n",
    "        self._betas = [np.random.normal(size=(num_features,)) for _ in range(self._num_actions)]\n",
    "\n",
    "    def fit_offline(self, logs):\n",
    "        samples_y, samples_x = collect_logs_b_post(num_actions, logs)\n",
    "        self._betas = build_models(self._num_features, samples_y, samples_x)\n",
    "\n",
    "    def policy(self, context):\n",
    "        \"\"\" Decide which post to display \"\"\"\n",
    "        viewing_max = -np.inf()\n",
    "        for action in range(self._num_actions):\n",
    "            viewing_hat = contact @ self._betas[action] # estimated viewing time\n",
    "            if viewing_hat > viewing_max:\n",
    "                action_best = action\n",
    "                viewing_max = viewing_hat\n",
    "        return action_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and evaluate the greedy recommender\n",
    "\n",
    "Since we're trying to maximize viewing time, a natural metric to track is the average viewing time per post. We'll take the mean over a day, since that's the period over which we're training the model.\n",
    "\n",
    "We'll run a simulation for 30 days and see how it performs. The simulation uses `num_features = 5` and `num_actions = 30`.\n",
    "\n",
    "![png](./05-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Note that contextual bandits focus only on the one-step (short-term) reward. For instance, if the reward from one post depended on the previously viewed post, that would be entirely missed.\n",
    "\n",
    "---\n",
    "\n",
    "This kind of system works pretty well. However, it is missing the exploration aspect! We'll fix this with an epsilon-greedy recommender.\n",
    "\n",
    "## Explore actions with epsilon-greedy\n",
    "\n",
    "The problem with the greedy algorithm is not enough exploring. What if showing a different post would have been better? You'd never know, because the system always dislays the one that it thinks is the best, with no allowance for uncertainty. We're missing the *counterfactual*.\n",
    "\n",
    "### Missing counterfactuals degrade predictions\n",
    "\n",
    "Let's see the effect of missing counterfactuals. Imagine the recommender system logged the following three samples from displaying post #1 three times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "]\n",
    "\n",
    "rewards = [\n",
    "    0.6,\n",
    "    0.9,\n",
    "    1.3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit a model to this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.9, 1.3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(contexts)\n",
    "y = np.array(rewards)\n",
    "beta_1 = np.linalg.pinv(x.T @ x) @ (x.T @ y)\n",
    "beta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say User A with `[0, 0, 1]` arrives. THis happens to be the third user, so we predict `[0, 0, 1] @ beta_1 = 1.3` as the viewing time.\n",
    "\n",
    "However, imagine that the third user had never been shown post #1, so our data was missing that third row - we didn't have the counterfactual. Then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_m=array([0.6, 0.9, 0. ]) -> predicted viewing time 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contexts = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "]\n",
    "\n",
    "rewards = [\n",
    "    0.6,\n",
    "    0.9,\n",
    "]\n",
    "\n",
    "x = np.array(contexts)\n",
    "y = np.array(rewards)\n",
    "beta_m = np.linalg.pinv(x.T @ x) @ (x.T @ y)\n",
    "print(f\"{beta_m=} -> predicted viewing time {beta_m @ np.array([0, 0, 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is obviously a pretty bad prediction.\n",
    "\n",
    "#### Feedback Loops\n",
    "\n",
    "This can result in fedback loops - the system won't ever show post #1 to users like A, which means the data is missing, meaning it won't show them the post, meaning the data is missing...\n",
    "\n",
    "In practice the feedback loops can be more subtle. You should always behave as though they might be present.\n",
    "\n",
    "### Exploring with epsilon-greedy to collect counterfactuals\n",
    "\n",
    "We would like some experimentation. We can use the epsilon-greedy algorithm from before. Recall: the process is to be greedy 90% (or whatever) of the time and choose a random post the other 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderEpsilonGreedy:\n",
    "    def __init__(self, num_features, num_actions, epsilon=0.1) -> None:\n",
    "        self._num_features = num_features\n",
    "        self._num_actions = num_actions\n",
    "        self._epsilon = epsilon\n",
    "    \n",
    "    def reset(self):\n",
    "        self._betas = [np.random.normal(size=(num_features,)) for _ in range(self._num_actions)]\n",
    "\n",
    "    def fit_offline(self, logs):\n",
    "        samples_y, samples_x = collect_logs_b_post(num_actions, logs)\n",
    "        self._betas = build_models(self._num_features, samples_y, samples_x)\n",
    "\n",
    "    def policy(self, context):\n",
    "        \"\"\" Decide which post to display \"\"\"\n",
    "        viewing_max = -np.inf()\n",
    "        if np.random.uniform(0, 1) < self._epsilon:\n",
    "            # choose a random one\n",
    "            action_best = np.random.randint(0, self._num_actions)\n",
    "        else:\n",
    "            # otherwise be greedy\n",
    "            for action in range(self._num_actions):\n",
    "                viewing_hat = contact @ self._betas[action] # estimated viewing time\n",
    "                if viewing_hat > viewing_max:\n",
    "                    action_best = action\n",
    "                    viewing_max = viewing_hat\n",
    "        return action_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](./sweet2023-ch05-07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore parameters with Thompson sampling\n",
    "\n",
    "Thompson sampling explores more efficiently the epsilon-greedy, exploring a lot when there is a lot of uncertaintly and little when there is litle.\n",
    "\n",
    "This requires changes to both the online and offline portions of the model.\n",
    "\n",
    "1. Each day, build a varied set of models, called the *ensemble*\n",
    "1. Put the entire ensemble of models online\n",
    "1. For each decision, the policy randomly selects a model from the ensemvle, then displays the post predicted by that mode to have the highest viewing time\n",
    "\n",
    "At decision time, Thompson sampling selects a model rather than randomly choosing an action, like we did with epsilon-greedy. In this case, Thompson sampling is an exploration over parameters and epsilon-greedy is exploration over actions.\n",
    "\n",
    "### Create an ensemble of prediction models\n",
    "\n",
    "If you run the fit using different inputs (logged values), you'll get different outputs. What you can do is take a single set of logged values and create 10 bootstrapped samples from it and fit a model for each bootstrapped sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderThompsonSampling:\n",
    "    def __init__(self, num_features, num_actions, num_bs_samples) -> None:\n",
    "        self._num_features = num_features\n",
    "        self._num_actions = num_actions\n",
    "        self._num_bs_samples = num_bs_samples\n",
    "    \n",
    "    def reset(self):\n",
    "        self._betas = []\n",
    "        for _ in range(self._num_actions):\n",
    "            self._betas.append([\n",
    "                np.random.normal(size=(num_features,)) for _ in range(self._num_actions)\n",
    "            ])\n",
    "\n",
    "    def _bs_sample(self, samples_y, samples_x):\n",
    "        bs_samples_y = []\n",
    "        bs_samples_x = []\n",
    "        for action in range(self._num_actions):\n",
    "            y = np.array(samples_y[action])\n",
    "            x = np.array(samples_x[action])\n",
    "            if len(y) > 0:\n",
    "                i = np.random.randint(0, len(y), size=(len(y),))\n",
    "                y = y[i]\n",
    "                x = x[i,:]\n",
    "            bs_samples_y.append(y)\n",
    "            bs_samples_x.append(x)\n",
    "        return bs_samples_y, bs_samples_x\n",
    "\n",
    "    def fit_offline(self, logs):\n",
    "        fit_logs = logs\n",
    "        samples_y, samples_x = collect_logs_by_action(num_actions, fit_logs)\n",
    "        self._betas = []\n",
    "        for _ in range(self._num_bs_samples):\n",
    "            bs_samples_y, bs_samples_x = self._bs_sample(samples_y, samples_x)\n",
    "            self._betas.append(build_models(self._num_features, bs_samples_y, bs_samples_x))\n",
    "\n",
    "    def policy(self, context):\n",
    "        \"\"\" Decide which post to display \"\"\"\n",
    "        i_beta = np.random.randint(0, len(self._betas))\n",
    "        beta = self._betas[i_beta]\n",
    "        viewing_max = -np.inf()\n",
    "        for action in range(self._num_actions):\n",
    "            viewing_hat = context @ self._betas[action] # estimated viewing time\n",
    "            if viewing_hat > viewing_max:\n",
    "                action_best = action\n",
    "                viewing_max = viewing_hat\n",
    "        return action_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](./sweet2023-ch05-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thompson sampling has optimal regret ($T^{\\frac{1}{2}}$, where $T$ is the fitting time).\n",
    "\n",
    "### Randomized probability matching\n",
    "\n",
    "Thompson sampling achieves higher business metrcis because it is more nuanced in its exploration. Since each model was fit with slightly different data, it will give slightly different outputs. For instance, say the following are the results of one run of the model:\n",
    "\n",
    "![png](./sweet2023-ch05-11.png)\n",
    "\n",
    "7 / 10 models predict the post #1 is the best. Since we're choosing the models at random, that means that we will select that 70% of the time; the other 30% of the time we select post #2. We are selecting an action according to the rule\n",
    "\n",
    "$$\n",
    "p(\\text{action}) = p_{\\text{best}}(\\text{action})\n",
    "$$\n",
    "\n",
    "## Validate the CB\n",
    "\n",
    "You probably want to run an A/B test whenever you're changing the system like that. Jsut be sure to run the AB test against the *peak* of the post-CB changes to allow for the time that it takes to actually improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
